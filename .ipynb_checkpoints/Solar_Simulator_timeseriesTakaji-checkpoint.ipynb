{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bb047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from db_form import parameters_form           # Yoni's form code.\n",
    "from db_dataverse import SampleDataverseTable # Dataverse code based on scripts by Felix.\n",
    "from db_dataverse import JVScanDataverseTable # \n",
    "\n",
    "from datetime import date, datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "import lmfit as lm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f12d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ Step 1 $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "#   Database parameters for the sample database.                         #\n",
    "#   For Sample_Data on  Perovskite Data Developer, Verde Technologies.   #\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "\n",
    "# It may be necessary to use the 'Connect' command in Powershell to change the user before running this cell.\n",
    "#crm_url =  \"https://orgc25b23b3.api.crm.dynamics.com/\"        # Randall Headrick's Environment at UVM.\n",
    "crm_url = \"https://perovskitedevelop.api.crm.dynamics.com/\"    # Perovskite Data Developer Environment at VerdeTechnologies. \n",
    "\n",
    "#sample_table_logical_name =  \"cr69a_sampledatav2s\"\n",
    "sample_table_logical_name =  \"crf3d_sample_datas\"               # Perovskite Data Developer, Dataverse table.\n",
    "\n",
    "# This is not a complete list, only a few that might be helpful to identify the sample.\n",
    "Sample_table_logical_names = {\n",
    "    \"Sample ID\": 'crf3d_sampleid', \n",
    "    \"Operator\": 'crf3d_operatorname', \n",
    "    \"Perovskite Composition\": 'crf3d_perovskitecomposition', \n",
    "    \"HTL Material\": 'crf3d_htlmaterial', \n",
    "    \"ETL Material\": 'crf3d_etlmaterial',\n",
    "    \"Top Capping Material\": 'crf3d_topcappingpassivationmaterial', \n",
    "    \"Bottom Capping Material\": 'crf3d_bottomcappingpassivationmaterial', \n",
    "    \"Bulk Passivation Materials\": 'new_bulkpassivationmaterial', \n",
    "    \"Is Encapsulated\": 'crf3d_isencapsulated'\n",
    "}\n",
    " \n",
    "# View a list of samples in the database.\n",
    "last_num= 1500  ################### The number of Sample records to view, most recent first.############\n",
    "sample_table = SampleDataverseTable(crm_url, sample_table_logical_name, col_logical_names=Sample_table_logical_names)\n",
    "sample_ids, sample_recent_values, result = sample_table.recent_entries(last_num)\n",
    "# print(sample_ids)\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - #\n",
    "\n",
    "\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ Step 2 $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "#   Database parameters for the jv scan database.                        #\n",
    "#   For J-V_Scan_Data on  Perovskite Data Developer, Verde Technologies. #\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "\n",
    "#JV_scan_table_logical_name = \"cr69a_jv_test_data_v3s\"\n",
    "JV_scan_table_logical_name = \"crf3d_jv_test_datas\"              # Perovskite Data Developer, Dataverse table.\n",
    "\n",
    "col_logical_names = {\n",
    "    'sample_id': 'crf3d_sample_id',\n",
    "    'elapsed_time': 'crf3d_elapsed_time_sec',\n",
    "    'base_time': 'crf3d_base_time_sec',  # New base_time value.\n",
    "    'test_id': 'crf3d_test_id',\n",
    "    'i_ph_suns': 'crf3d_iph_suns',\n",
    "    'voc_v': 'crf3d_voc_v',\n",
    "    'mpp_v': 'crf3d_mpp_v',\n",
    "    'jsc_ma': 'crf3d_jsc_macm2',\n",
    "    'rsh': 'crf3d_rsh',\n",
    "    'rser': 'crf3d_rser',\n",
    "    'ff': 'crf3d_ff_pct',\n",
    "    'pce': 'crf3d_pce_pct',\n",
    "    'operator': 'crf3d_operator_name',\n",
    "    'scan_type': 'crf3d_scan_type',\n",
    "    'lab_location': 'crf3d_location',\n",
    "    'cell_number': 'crf3d_cell_number',\n",
    "    'module': 'crf3d_module',\n",
    "    'masked': 'crf3d_masked',\n",
    "    'mask_area': 'crf3d_mask_area_cm2',\n",
    "    'temp_c': 'crf3d_temperature_c',  # New.\n",
    "    'hum_pct': 'crf3d_humidity_pct', # New.\n",
    "    'four_wire_mode': 'crf3d_four_wire_mode', # New.\n",
    "    'scan_data_path': 'crf3d_scan_path' # New.\n",
    "}\n",
    "image_column_name = 'new_jv_scan_plot'  # Optional column.\n",
    "\n",
    "# Set up the J-V_Test_Data table.\n",
    "jv_test_table = JVScanDataverseTable(crm_url=crm_url, table_name=JV_scan_table_logical_name, col_logical_names=col_logical_names)\n",
    "\n",
    "# Retrieve the last num_vals of the jv test data.\n",
    "num_vals= 5000\n",
    "jv_test_ids, jv_test_recent_values, jv_test_result = jv_test_table.recent_entries(num_vals)\n",
    "#print(jv_test_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_recent_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2012118",
   "metadata": {},
   "outputs": [],
   "source": [
    "jv_test_recent_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jv_test_recent_values['scan_data_path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05400907",
   "metadata": {},
   "outputs": [],
   "source": [
    "### X.X ###\n",
    "# Everything should be relative to jupyter_notebook_path.  \n",
    "# There will be other folders created,such as ../{operator}_{date}\n",
    "jupyter_notebook_path = os.getcwd()\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ Sample ID filtering $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "#                                                                                                         #\n",
    "#                           Change the filters below to select a list of samples.                         #\n",
    "#                                                                                                         #\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "\n",
    "sample_filter_1 = '01272025'       # Change this to filter a range of samples.        Use '' to match everything.\n",
    "sample_filter_2 = ''      # Use this one to narrow or broaden the filter.    Use '' to match everything. \n",
    "sample_filter_operator = 'and'       # Operator for sample_filter_1 and _2.\n",
    "\n",
    "if sample_filter_operator == 'and':\n",
    "    sample_id_list = [sample_id for sample_id in sample_ids if (sample_filter_1 in sample_id) and (sample_filter_2 in sample_id)]\n",
    "elif sample_filter_operator == 'or':\n",
    "    sample_id_list = [sample_id for sample_id in sample_ids if (sample_filter_1 in sample_id) or (sample_filter_2 in sample_id)]\n",
    "else:\n",
    "    sample_id_list = []\n",
    "    raise Exception(\"sample_filter_operator must be either \\'and\\' or \\'or\\'.\")\n",
    "\n",
    "sample_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bcd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ Get the operator name $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "#                                                                                                         #\n",
    "#                       Use the 'operator' for the first 'sample_id' as the default.                      #\n",
    "#                                                                                                         #\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "\n",
    "jv_test_operator_list = list(jv_test_recent_values[ 'operator' ])\n",
    "jv_test_sample_id_list = list(jv_test_recent_values[ 'sample_id' ])\n",
    "ind = jv_test_sample_id_list.index(sample_id_list[0])                # index of the first sample in sample_id_list\n",
    "default_operator =   str(jv_test_operator_list[ind])\n",
    "\n",
    "operator = input(\"Operator name: \") or default_operator\n",
    "if operator == default_operator:\n",
    "    print(f\"                {operator}\")\n",
    "\n",
    "dir_path_local = os.path.normpath(os.path.join(jupyter_notebook_path, f\"../Reports/{operator}\")) \n",
    "\n",
    "today = date.today()\n",
    "#today = date(2025, 2, 26)\n",
    "path = dir_path_local + \"_\" + today.strftime(\"%m%d%y\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ada70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ Form parameters $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "# Operator        # This will be a fixed value, changeable in the cell above.                    #\n",
    "# Sample names    # Select multiple samples                                                      #\n",
    "# Parameters to plot: PCE, FF, Voc, Jsc, MPP, Rser, Rshunt   # radio buttons.                    #\n",
    "# Plot type.  Choice of either Time series (one sample) or Box plot (compares up to 4 samples).  #\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "\n",
    "# The questions json file can be anywhere, but it will usually be in the directory with this Notebook.\n",
    "questions_file_main= os.path.join(jupyter_notebook_path, \"main_questions.json\")\n",
    "\n",
    "form = parameters_form(persistent=True, dir_path_local=dir_path_local, \n",
    "                               questions_file_main=questions_file_main, checkbox_values=sample_id_list)\n",
    "print(form.checkbox_values)\n",
    "form.display_question_canvas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure the responses are what you want.\n",
    "print(form.responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8198d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### X.X  ###\n",
    "# Convert the form responses into a dictionary for easier indexing.\n",
    "form_questions = [question['question'] for question in form.questions]\n",
    "\n",
    "form_responses_new = list(form.responses)\n",
    "sample_id_filter = form_responses_new[1] # position [1] refers to the sample id checkbox responses.\n",
    "form_responses_new[1] = [id for indx,id in enumerate(sample_id_list) if sample_id_filter[indx] == True]\n",
    "form_responses_dictionary = dict(zip(form_questions, form_responses_new))\n",
    "\n",
    "\n",
    "print(form_responses_dictionary)\n",
    "print(\"-\")\n",
    "\n",
    "# Check if the form responses are valid.\n",
    "if len(form_responses_dictionary['Sample names? (select up to four)']) == 0:\n",
    "    raise Exception(\"At least one sample must be selected.\")\n",
    "elif form_responses_dictionary[\"Plot type?\"] == \"Box plot\":\n",
    "    if len(form_responses_dictionary['Sample names? (select up to four)'])  > 4:\n",
    "        raise Exception(\"No more than four samples should be selected for Box plot.\")\n",
    "elif form_responses_dictionary[\"Plot type?\"] == \"Time series\":\n",
    "        if len(form_responses_dictionary['Sample names? (select up to four)'])  > 1:\n",
    "            raise Exception(\"Only one sample should be selected for Time series.\")\n",
    "             \n",
    "print(\"Form responses are valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_responses_dictionary['Sample names? (select up to four)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2652cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp conversion functions.\n",
    "\n",
    "def epoch_to_timestamp(ts):\n",
    "    '''Convert a unix epoch to a YYYY-MM-DD hh:mm:ss timestamp'''\n",
    "    return datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def timestamp_to_epoch(dt):\n",
    "    '''Convert YYYY-MM-DD hh:mm:ss timestamp string to a unix epoch'''\n",
    "    datetime_obj = datetime.strptime(dt, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return  datetime_obj.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d88fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ Create a list of Dataframes $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "#                                                                                                         #\n",
    "#               Each dataframe in 'jv_test_data_list' holds JV data for a different sample.               #\n",
    "#                  The corresponding sample ids are in the list  'sample_ids_selected'.                   #\n",
    "#                                                                                                         #\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "sample_ids_selected = form_responses_dictionary['Sample names? (select up to four)']\n",
    "jv_test_data_list = []    # This list will hold one dataframe of JV data for each sample_id.\n",
    "for sample_id in sample_ids_selected:\n",
    "   jv_test_data_list.append(jv_test_recent_values[jv_test_recent_values[\"sample_id\"]==sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa170c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ First look at the JV data $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "#                                                                                                         #\n",
    "#                The simplest plot is time. Plot the JV data for the first selected sample.               #\n",
    "#                                                                                                         #\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "\n",
    "# Look at the first sample in the selection list.\n",
    "sample_id = sample_ids_selected[0]\n",
    "df = jv_test_data_list[0]\n",
    "\n",
    "# Select just the columns I need for the analaysis.\n",
    "df2 = df[['cell_number','pce', 'voc_v', 'ff', \n",
    "          'jsc_ma', 'scan_type', 'mpp_v', 'rser', 'rsh']].copy()  # to do: add 'test_status' to the list of columns.\n",
    "\n",
    "# Reconstruct the timestamp from the unix epoch.\n",
    "tsl = df['base_time'].astype(float)+60.0*df['elapsed_time'].astype(float)\n",
    "timestamp_series = tsl.apply(epoch_to_timestamp)\n",
    "\n",
    "# Insert the timestamp into the dataframe with column heading \"measured_on\".\n",
    "df2.insert(0,\"measured_on\", timestamp_series)\n",
    "MIN_BASE_TIME = min(df['base_time'].astype(float))\n",
    "df2.insert(1,\"time_hrs\", (tsl-MIN_BASE_TIME)/3600)\n",
    "\n",
    "# Split the data into forward and reverse scan types.\n",
    "df2_fwd = df2.loc[df['scan_type'] == 'F']\n",
    "df2_rev = df2.loc[df['scan_type'] == 'R']\n",
    "\n",
    "# Selected parameter to plot.\n",
    "parameter_ylabel = form_responses_dictionary['Parameter to plot?']\n",
    "print(parameter_ylabel)\n",
    "if parameter_ylabel == 'PCE (%)':\n",
    "    parameter_to_plot = \"pce\"\n",
    "elif parameter_ylabel == 'FF (%)':\n",
    "    parameter_to_plot = \"ff\"\n",
    "elif parameter_ylabel == 'Voc (V)':\n",
    "    parameter_ylabel = r'V$_{oc}$ (V)'\n",
    "    parameter_to_plot = \"voc_v\"\n",
    "elif parameter_ylabel == 'Jsc (mA/cm^2)':\n",
    "    parameter_ylabel = r'J$_{sc}$ (mA/cm$^2$)'\n",
    "    parameter_to_plot = \"jsc_ma\"\n",
    "elif parameter_ylabel == 'MPP (V)':\n",
    "    parameter_to_plot = \"mpp_v\"\n",
    "elif parameter_ylabel == 'Rser (Ohm-cm^2)':\n",
    "    parameter_ylabel = r'R$_{ser}$ (Ohm-cm$^2$)'\n",
    "    parameter_to_plot = \"rser\"\n",
    "elif parameter_ylabel == 'Rsh (Ohm-cm^2)':\n",
    "    parameter_ylabel = r'R$_{sh}$ (Ohm-cm$^2$)'\n",
    "    parameter_to_plot = \"rsh\"\n",
    "else:\n",
    "    raise Exception(\"Invalid parameter ylabel\")\n",
    "print(parameter_ylabel)\n",
    "print(parameter_to_plot)\n",
    "\n",
    "# Set the font.\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Make the plot.\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "direction_response = form_responses_dictionary[\"Scan direction?\"] \n",
    "# If we are plotting both Fwd and Rev, then don't label individual cell numbers.\n",
    "if direction_response == \"both\":\n",
    "    alpha_val = 0.5\n",
    "    plt.plot(df2_rev[\"time_hrs\"], df2_rev[parameter_to_plot].astype(float), 'co', label=\"Reverse sweep\", alpha=alpha_val)\n",
    "    plt.plot(df2_fwd[\"time_hrs\"], df2_fwd[parameter_to_plot].astype(float), 'ro', label=\"Forward sweep\", alpha=alpha_val)\n",
    "# If we are plotting only one direction then we will label individual cell numbers.\n",
    "elif (direction_response == \"forward\") or (direction_response == \"reverse\"):\n",
    "    if direction_response == \"forward\":\n",
    "        dir = \"Fwd\"\n",
    "        symbols = ['.', 's--', 'o--', '^--', 'v--', '*--', '>--']\n",
    "        alpha_val = 0.75\n",
    "        for cellnum in range(1,7):\n",
    "            df2_onecell = df2_fwd.loc[df2_fwd['cell_number'] == str(cellnum)]\n",
    "            if len(df2_onecell) > 0:\n",
    "                plt.plot(df2_onecell[\"time_hrs\"], df2_onecell[parameter_to_plot].astype(float), \n",
    "                     symbols[cellnum], label=f\"{dir} cell #{cellnum}\", alpha=alpha_val)\n",
    "    else:\n",
    "        dir = \"Rev\"\n",
    "        symbols = ['.', 's--', 'o--', '^--', 'v--', '*--', '>--']\n",
    "        alpha_val = 0.75\n",
    "        for cellnum in range(1,7):\n",
    "            df2_onecell = df2_rev.loc[df2_rev['cell_number'] == str(cellnum)]\n",
    "            df2_onecell = df2_onecell.sort_values(by='time_hrs')\n",
    "            if len(df2_onecell) > 0:\n",
    "                #\n",
    "                # try:\n",
    "                #     xdata = np.array(df2_onecell[\"time_hrs\"].astype(float))\n",
    "                #     # print(\"xdata=\", xdata)\n",
    "                #     ydata = np.array(df2_onecell[parameter_to_plot].astype(float))\n",
    "                #     # print(\"ydata=\", ydata)\n",
    "                #     model = lm.Model(Constant) - lm.Model(Stretch_Exp)\n",
    "                #     params = model.make_params()\n",
    "                #     params['constant'].set(ydata[-1],min=0.0001,max=10)\n",
    "                #     params['amp'].set(-ydata[0]+ydata[-1])\n",
    "                #     params['tau'].set(200,min=20,max=9999.9)\n",
    "                #     params['shift'].set(xdata[0])\n",
    "                #     params['beta'].set(1.0,min=0.8,max=1.2)\n",
    "                #     print(\"xdata=\",xdata,\" \\nydata=\",ydata)\n",
    "                #     result = model.fit(ydata,params,x=np.array(xdata))\n",
    "                #     y0 = result.best_fit\n",
    "                #     print(\" \\ny0=\",y0)\n",
    "                #     print(result.best_values)\n",
    "                #     # result.plot_fit(show_init=True)\n",
    "                #     plt.plot(xdata,y0,'-')\n",
    "                #     print(\"----\")\n",
    "                # except:\n",
    "                #     print(\"Error for cell # \",cellnum)\n",
    "                #     print(\"----\")\n",
    "                #\n",
    "                plt.plot(df2_onecell[\"time_hrs\"], df2_onecell[parameter_to_plot].astype(float), \n",
    "                     symbols[cellnum], label=f\"{dir} cell #{cellnum}\", alpha=alpha_val)\n",
    "               \n",
    "\n",
    "\n",
    "plt.xlabel(\"Elapsed time (hours)\")\n",
    "plt.ylabel(parameter_ylabel)\n",
    "plt.title(sample_id, fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid()\n",
    "plt.ylim(0,20)\n",
    "ax.set_yticks([0,4,8,12,16,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ebc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"                               \",color.DARKCYAN + color.BOLD + sample_id)\n",
    "df2[df2['cell_number']=='5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"                               \", color.DARKCYAN + color.BOLD + sample_id)\n",
    "df2_rev.sort_values(by='time_hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47045408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ Data clumping parameters $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "#                                                                                                         #\n",
    "#                       They are used to group data points in the time-series plot.                       #\n",
    "#                                                                                                         #\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#\n",
    "min_gap_width   = 1.0   # hours.  Clumps must have a gap between them of at least this amount or they will be combined.\n",
    "max_clump_width = 2.0   # hours.  If measurments in the same clump are separated by more than this amount, an Exception will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cecdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#        \n",
    "# Approach: Work with the list of DataFrames 'jv_test_data_list'.\n",
    "#           Break the dataframes down into 'clumps'.\n",
    "#           In order to keep it simple, add a new column to each dataframe with the clump number.\n",
    "#           We don't need to distinguish between 'F' and 'R' sweeps. They can be together in the same clump.\n",
    "#\n",
    "def dataframe_clumping(jv_test_data_list):\n",
    "    '''Add a column to each DataFrame in the list with the clump number for each JV measurement'''\n",
    "    jv_test_data_list_2 = [] # Output list to be built in the code below.\n",
    "    for df in jv_test_data_list:\n",
    "        # Select just the columns I need for the analaysis.\n",
    "        df2 = df[['cell_number','pce', 'voc_v', 'ff', \n",
    "                  'jsc_ma', 'scan_type', 'mpp_v', 'rser', 'rsh']].copy()  # to do: add 'test_status' to the list of columns.\n",
    "        \n",
    "        # Reconstruct the timestamp from the unix epoch.\n",
    "        tsl = df['base_time'].astype(float)+60.0*df['elapsed_time'].astype(float)\n",
    "        timestamp_series = tsl.apply(epoch_to_timestamp)\n",
    "        \n",
    "        # Insert the timestamp into the dataframe with column heading \"measured_on\".\n",
    "        df2.insert(0,\"measured_on\", timestamp_series)\n",
    "        df2.insert(1,\"time_hrs\", (tsl-min(df['base_time'].astype(float)))/3600)\n",
    "\n",
    "        # Sort the dataframe by time.\n",
    "        df2_sorted = df2.sort_values(by='time_hrs')\n",
    "\n",
    "        # Convert the times into a list.\n",
    "        # column_names = df2_sorted.columns\n",
    "        # print(column_names)\n",
    "        \n",
    "        # Compute the time intervals.\n",
    "        time_hrs_list = df2_sorted['time_hrs'].to_list()\n",
    "        time_hrs_list_shifted = [0] + time_hrs_list[:-1]\n",
    "        time_intervals = [t2-t1 for t2,t1 in zip(time_hrs_list, time_hrs_list_shifted)]\n",
    "\n",
    "        # Assign the clump numbers.\n",
    "        clump_assignments = [0] # The first measurment is in clump 0.\n",
    "        clump_elapsed_time_list = [0] # How long since the first measurement in the clump.\n",
    "        clump_number = 0\n",
    "        # Skip the first time interval in the for loop below. \n",
    "        clump_elapsed_time = 0\n",
    "        for ind in range(1,len(time_intervals)):\n",
    "            if time_intervals[ind] >= min_gap_width:\n",
    "                clump_number += 1\n",
    "                clump_elapsed_time = 0\n",
    "            else:\n",
    "                clump_elapsed_time += time_intervals[ind]\n",
    "                if clump_elapsed_time > max_clump_width:\n",
    "                    raise Exception(f\"clump_elapsed_time {round(clump_elapsed_time,5)} is larger than the max_clump_width  of {max_clump_width}\")\n",
    "            clump_assignments.append(clump_number)\n",
    "            clump_elapsed_time_list.append(clump_elapsed_time)\n",
    "\n",
    "        # Insert the clump numbers into the dataframe with heading 'clump_number'\n",
    "        df2_sorted.insert(2,\"clump_number\", clump_assignments)\n",
    "        # df2_sorted.insert(3,\"clump_elapsed_time\", clump_elapsed_time_list)\n",
    "\n",
    "        # Add the modifed Dataframe to the new jv test dat list.\n",
    "        jv_test_data_list_2.append(df2_sorted)\n",
    "\n",
    "    return jv_test_data_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137dae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jv_test_data_list_2 = dataframe_clumping(jv_test_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9374b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "jv_test_data_list_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cdebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSON file and returns its content as a Python dictionary.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the JSON data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{file_path}'\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in '{file_path}'\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "         print(f\"An unexpected error occurred: {e}\")\n",
    "         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e330ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ff161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the file name below as needed.\n",
    "file_path = dir_path_local + '/' + 'Seid_degradation_tests_021625_V2.json'\n",
    "#file_path = 'C:' + '/' + 'Users' + '/'+'takaj'+'/' + 'Desktop' + '/' + 'Reports' + '/' + 'Seid_degradation_tests_021625.json'\n",
    "tests = read_json_file(file_path)\n",
    "\n",
    "if tests:\n",
    "    # Process the data\n",
    "    print(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract lists of starttimes and endtimes.\n",
    "start_time_list = [test['start'] for test in tests if 'test' in test]\n",
    "end_time_list = [test['end'] for test in tests if 'test' in test]\n",
    "samples_list =  [test['samples'] for test in tests if 'test' in test]\n",
    "      \n",
    "# check to make sure there are the same number of start and end times.\n",
    "start_count = len(start_time_list)\n",
    "end_count  = len(end_time_list)\n",
    "if start_count == end_count:\n",
    "    print(f\"Found {start_count} start and end times.\")\n",
    "else:\n",
    "    raise Exception(f\" The number of start times ({start_count}) and end times ({end_count}) are different.\")\n",
    "\n",
    "# Combine the start and end times in a list of tuples\n",
    "start_end_time_list = [(s,e) for s, e in zip(start_time_list, end_time_list)]\n",
    "\n",
    "# Also make a Dataframe with all the key:value pairs\n",
    "keys = list(tests[0].keys())\n",
    "tests_df = pd.DataFrame(tests, columns=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2978c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_df['samples'][1]  # This is the df of stability tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77001d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error boxes function\n",
    "def make_error_boxes(ax, xdata, xerror, yerror_25, yerror_75, facecolor='r', edgecolor='none', alpha=0.5):\n",
    "    '''Create boxes with the same x-widths and absolute upper and lower edges.'''\n",
    "    errorboxes = []\n",
    "    xe = xerror\n",
    "    for x, ye25, ye75 in zip(xdata, yerror_25, yerror_75):\n",
    "        # print(f' x={x}, ye25={ye25}, ye75={ye75} ')\n",
    "        rect = patches.Rectangle((x - xe, ye25), 2.0*xe, ye75 - ye25, facecolor=facecolor, edgecolor=edgecolor, alpha=alpha)\n",
    "        errorboxes.append(rect)\n",
    "    \n",
    "    for box in errorboxes:\n",
    "        ax.add_patch(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_elapsed_time(timestamp, min_base_time):\n",
    "    '''Return the elapsed time in hours from the timestamp and the offset epoch'''\n",
    "    return float(timestamp_to_epoch(timestamp) -  min_base_time)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b109ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the list of relative start and end times of the stability tests.\n",
    "start_end_times_list = []\n",
    "for ind in range (len(tests_df)):\n",
    "    if sample_id in tests_df['samples'][ind]:\n",
    "        ss = timestamp_to_elapsed_time(tests_df['start'][ind], MIN_BASE_TIME)\n",
    "        ee = timestamp_to_elapsed_time(tests_df['end'][ind], MIN_BASE_TIME)\n",
    "        test_type = tests_df['test'][ind]\n",
    "        print(ind, ss, ee)\n",
    "        start_end_times_list.append([ss, ee, test_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fill_between time_ranges from the time stamps.\n",
    "# These are the times of the degradation tests\n",
    "# times are in hours, relative to MIN_BASE_TIME.\n",
    "fill_time_ranges = [[(timestamp_to_epoch(s)-MIN_BASE_TIME)/3600,\n",
    "                    (timestamp_to_epoch(e)-MIN_BASE_TIME)/3600]  \n",
    "                    for s,e in zip(start_time_list, end_time_list)]\n",
    "\n",
    "# Filter these fill_time_ranges by sample_id.  \n",
    "\n",
    "filtered_fill_range_list = [ftr for sl, ftr in zip(samples_list, fill_time_ranges) if sample_id in sl]\n",
    "filtered_test_duration_list =  [ttr[1]-ttr[0] for ttr in filtered_fill_range_list]\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"sample_id:                 \", sample_id)\n",
    "print(\"Stability test time ranges:\", filtered_fill_range_list )\n",
    "print(\"Stability test durations:  \", filtered_test_duration_list)\n",
    "\n",
    "# The data time ranges can be found from the clump labels.\n",
    "\n",
    "df_sample = jv_test_data_list_2[0]    # Assume just one sample_id.\n",
    "clump_max = max(df_sample['clump_number'])\n",
    "\n",
    "time_ranges = []\n",
    "for clump_index in range(clump_max+1):\n",
    "    df_clump = df_sample[df_sample['clump_number'] == clump_index]\n",
    "    time_ranges.append((min(df_clump['time_hrs']), max(df_clump['time_hrs'])))\n",
    "\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"Measurement time ranges (clumps):\", time_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40538ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmfit models\n",
    "\n",
    "# Constant function\n",
    "def Constant(x,constant):\n",
    "    return constant\n",
    "\n",
    "# Stretched Exponential\n",
    "def Stretch_Exp(x,amp,tau,shift,beta):\n",
    "    return amp*np.exp(-((x-shift)/tau)**beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1daede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plot\n",
    "\n",
    "# Split the data into forward and reverse scan types.\n",
    "df_sample_fwd = df_sample.loc[df['scan_type'] == 'F']\n",
    "df_sample_rev = df_sample.loc[df['scan_type'] == 'R']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "clump_median = []\n",
    "clump_median_time = []\n",
    "clump_champ = []\n",
    "for clump_index in range(clump_max+1):\n",
    "    df_clump = df_sample_rev[df_sample_rev['clump_number'] == clump_index]\n",
    "    xdata = list(df_clump['time_hrs'])\n",
    "    xdata = [float(x) for x in xdata]\n",
    "    ydata = list(df_clump['pce'])\n",
    "    ydata = [float(y) for y in ydata]\n",
    "    clump_median_time.append(np.median(xdata))\n",
    "    clump_median.append(np.median(ydata))\n",
    "    clump_champ.append(np.max(ydata))\n",
    "   \n",
    "    plt.plot(xdata, ydata, 'bo')\n",
    "    #\n",
    "plt.plot(xdata, ydata, 'bo', label=\"Reverse\")\n",
    "plt.plot(clump_median_time, clump_median, 'b--', label=\"Reverse median\")\n",
    "plt.plot(clump_median_time, clump_champ, 'b-.', label=\"Reverse champion\")\n",
    "# Also plot the  Forward data\n",
    "clump_median = []\n",
    "clump_median_time = []\n",
    "for clump_index in range(clump_max+1):\n",
    "    df_clump = df_sample_fwd[df_sample_fwd['clump_number'] == clump_index]\n",
    "    xdata = list(df_clump['time_hrs'])\n",
    "    ydata = list(df_clump['pce'])\n",
    "    ydata = [float(y) for y in ydata]\n",
    "    clump_median_time.append(np.median(xdata))\n",
    "    clump_median.append(np.median(ydata))\n",
    "    plt.plot(xdata, ydata, 'mo')\n",
    "plt.plot(xdata, ydata, 'mo', label=\"Forward\")\n",
    "plt.plot(clump_median_time, clump_median, 'm--', label=\"Forward median\")\n",
    "\n",
    "for test_times in start_end_times_list:\n",
    "    ss = test_times[0]\n",
    "    ee = test_times[1]\n",
    "    test_type = test_times[2]\n",
    "    yrange = np.array([0,100])\n",
    "    plt.fill_betweenx(yrange, ss, ee, alpha=0.55, label=f\"{test_type}\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(sample_id)\n",
    "plt.xlabel(\"Time (hrs)\")\n",
    "plt.ylabel(parameter_ylabel)\n",
    "plt.ylim(0,20)\n",
    "ax.set_yticks([0,4,8,12,16,20])\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104905fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef3ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    # #\n",
    "    # model = lm.Model(Constant) - lm.Model(Stretch_Exp)\n",
    "    # params = model.make_params()\n",
    "    # params['constant'].set(ydata[-1],min=0.0001,max=10)\n",
    "    # params['amp'].set(-ydata[0]+ydata[-1])\n",
    "    # params['tau'].set(100,min=20,max=9999.9)\n",
    "    # params['shift'].set(xdata[0])\n",
    "    # params['beta'].set(1.0,min=0.8,max=1.2)\n",
    "    # y0 = model.eval(params,x=np.array(xdata))\n",
    "    # print(\"xdata=\",xdata,\" \\nydata=\",ydata,\" \\ny0=\",y0)\n",
    "    # print(\"----\")\n",
    "    # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b59fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c141ce73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01c8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68a1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e8f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e5ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
